{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8d4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39624a2",
   "metadata": {},
   "source": [
    "Do ensure you have a vllm deployment ready! In my case I used notebook `2a. setup_vllm.ipynb` in google colab for my deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb59496",
   "metadata": {},
   "source": [
    "## Using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252e299c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://9398efd88ee3.ngrok-free.app/v1\",\n",
    "    api_key=\"token-abc123\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbf31a",
   "metadata": {},
   "source": [
    "## Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33cbb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a city that has been around for over 2,500 years\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import VLLMOpenAI\n",
    "\n",
    "llm = VLLMOpenAI(\n",
    "    openai_api_key=\"token-abc123\",\n",
    "    openai_api_base=\"https://9398efd88ee3.ngrok-free.app/v1\",\n",
    "    model_name=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    model_kwargs={\"stop\": [\".\"]},\n",
    ")\n",
    "print(llm.invoke(\"Rome is\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08630f52",
   "metadata": {},
   "source": [
    "OH NO! `vLLMOpenAI` has no tool binding capabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e577e3ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VLLMOpenAI' object has no attribute 'bind_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Use this tool to add two integers or floats.\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m a+b\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m vllm_agent = \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43madd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/OysterShell/.venv/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py:453\u001b[39m, in \u001b[36mcreate_react_agent\u001b[39m\u001b[34m(model, tools, prompt, response_format, pre_model_hook, post_model_hook, state_schema, config_schema, checkpointer, store, interrupt_before, interrupt_after, debug, version, name)\u001b[39m\n\u001b[32m    447\u001b[39m tool_calling_enabled = \u001b[38;5;28mlen\u001b[39m(tool_classes) > \u001b[32m0\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    450\u001b[39m     _should_bind_tools(model, tool_classes, num_builtin=\u001b[38;5;28mlen\u001b[39m(llm_builtin_tools))\n\u001b[32m    451\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tool_classes + llm_builtin_tools) > \u001b[32m0\u001b[39m\n\u001b[32m    452\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     model = \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBaseChatModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_tools\u001b[49m(tool_classes + llm_builtin_tools)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m    455\u001b[39m model_runnable = _get_prompt_runnable(prompt) | model\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# If any of the tools are configured to return_directly after running,\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;66;03m# our graph needs to check if these were called\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/OysterShell/.venv/lib/python3.12/site-packages/pydantic/main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'VLLMOpenAI' object has no attribute 'bind_tools'"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def add(a: int | float, b: int | float) -> str:\n",
    "    \"\"\"Use this tool to add two integers or floats.\"\"\"\n",
    "    return a+b\n",
    "\n",
    "vllm_agent = create_react_agent(llm, tools=[add])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666be4b9",
   "metadata": {},
   "source": [
    "Use `ChatOpenAI` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62691575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_openai = ChatOpenAI(\n",
    "    model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    temperature=0,\n",
    "    api_key=\"token-abc123\",\n",
    "    base_url=\"https://9398efd88ee3.ngrok-free.app/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40fba1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_agent = create_react_agent(llm_openai, tools=[add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11059791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-0aa133f80ab94d1198ba8468f538aadf', 'function': {'arguments': '{\"a\": 7, \"b\": 21}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 308, 'total_tokens': 330, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'system_fingerprint': None, 'id': 'chatcmpl-61a08f6ffba141bab406033572f012eb', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--680a53dd-3c48-4fc2-8440-36d16e48f055-0', tool_calls=[{'name': 'add', 'args': {'a': 7, 'b': 21}, 'id': 'chatcmpl-tool-0aa133f80ab94d1198ba8468f538aadf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 308, 'output_tokens': 22, 'total_tokens': 330, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='28', name='add', id='6ede4285-672f-4c15-9e90-5164b3d0f911', tool_call_id='chatcmpl-tool-0aa133f80ab94d1198ba8468f538aadf')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The result of the function call is 28.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 346, 'total_tokens': 357, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'system_fingerprint': None, 'id': 'chatcmpl-fcc3dac46d29409f8e71e5973b02309c', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--fe663199-7b77-448b-98fd-61da958a671d-0', usage_metadata={'input_tokens': 346, 'output_tokens': 11, 'total_tokens': 357, 'input_token_details': {}, 'output_token_details': {}})]}}\n"
     ]
    }
   ],
   "source": [
    "async for chunk in openai_agent.astream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is 7+21?\"}]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    # chunk['messages'].pretty_print()\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934bebe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oystershell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
